# Document Processing Service - Base Image with Heavy Dependencies
# 
# This base image contains all heavy, rarely-changing dependencies:
# - Java Runtime Environment (JRE 17)
# - Apache Tika server JAR
# - RapidOCR ONNX models
# - Heavy Python libraries (docling, onnxruntime, shared)
# - Optional: Hugging Face SmolVLM model (local VLM mode)
#
# Build with custom VLM mode:
# docker build -f Dockerfile.base --build-arg DOCLING_VLM_MODE=remote -t document-processing-base:latest .
#
FROM python-service-base:latest

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

# Set DOCLING_VLM_MODE early to control conditional build steps
# Default to 'local' if not provided, but can be overridden via build args
ARG DOCLING_VLM_MODE=local
ENV DOCLING_VLM_MODE=${DOCLING_VLM_MODE}

WORKDIR /app

# Install Java Runtime Environment, wget for Tika download, curl for healthchecks, git for HF downloads,
# and font packages for RapidOCR/Pillow text rendering
# These are system-level dependencies that rarely change
RUN for i in 1 2 3 4 5; do \
    find /etc/apt -type f \( -name 'sources.list' -o -name '*.list' -o -name '*.sources' \) -print0 | xargs -0 sed -i 's|http://|https://|g'; \
    apt-get update && \
    apt-get install -y --no-install-recommends --fix-missing \
        ca-certificates \
        libssl-dev \
        openjdk-17-jre-headless \
        wget \
        libgl1 \
        git \
        fontconfig \
        fonts-liberation \
        fonts-dejavu-core \
        fonts-wqy-microhei \
        fonts-wqy-zenhei && \
    update-ca-certificates && \
    rm -rf /var/lib/apt/lists/* && \
    java -version && \
    break || (echo "Retry $i/5 failed, waiting..." && sleep 5); \
  done

# Set JAVA_HOME and update PATH to include Java
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH="${JAVA_HOME}/bin:${PATH}"

# Configure font paths for RapidOCR and Pillow
# These fonts are used for text rendering and visualization in OCR operations
ENV FONTCONFIG_PATH=/etc/fonts
ENV FONTS_DIR=/usr/share/fonts

# Update font cache to ensure all installed fonts are available
# This prevents runtime font download attempts
RUN fc-cache -fv && \
    echo "Font cache updated successfully" && \
    echo "Available font directories:" && \
    fc-list : file | cut -d: -f1 | sort -u | head -20

# Pre-install Apache Tika server during build phase
ENV TIKA_VERSION=3.1.0
ENV TIKA_SERVER_JAR=/opt/tika-server/tika-server.jar
ENV TIKA_SERVER_ENDPOINT=http://localhost:9998

# Download and validate Tika Server JAR
RUN mkdir -p /opt/tika-server && \
    echo "Downloading Tika Server JAR version ${TIKA_VERSION}..." && \
    wget --quiet --timeout=60 --tries=3 \
    -O ${TIKA_SERVER_JAR} \
    "https://repo1.maven.org/maven2/org/apache/tika/tika-server-standard/${TIKA_VERSION}/tika-server-standard-${TIKA_VERSION}.jar" && \
    echo "Verifying download..." && \
    test -f ${TIKA_SERVER_JAR} && \
    JAR_SIZE=$(stat -c%s ${TIKA_SERVER_JAR}) && \
    echo "JAR downloaded successfully: $JAR_SIZE bytes" && \
    [ "$JAR_SIZE" -gt 50000000 ] && \
    chmod 644 ${TIKA_SERVER_JAR} && \
    echo "Tika JAR ready: ${TIKA_SERVER_JAR}"

# Set default Tika log path for build-time directory creation
ENV TIKA_LOG_PATH=/tmp/tika-logs

# Prepare Tika log directory and initial log file with proper permissions
RUN mkdir -p ${TIKA_LOG_PATH} && \
    touch ${TIKA_LOG_PATH}/tika.log && \
    chmod 755 ${TIKA_LOG_PATH} && \
    chmod 644 ${TIKA_LOG_PATH}/tika.log && \
    echo "Tika log directory and initial log file prepared: ${TIKA_LOG_PATH}/tika.log"

# RapidOCR models directory (pre-downloaded OCR models for offline operation)
ENV RAPIDOCR_MODELS_PATH=/opt/rapidocr-models

# Copy RapidOCR models from plugins/ directory
# REQUIRED: The following models MUST exist directly in plugins/rapidocr-models/:
#   - ch_PP-OCRv3_det_infer.onnx
#   - ch_PP-OCRv3_rec_infer.onnx
#   - ch_ppocr_mobile_v2.0_cls_infer.onnx
# The build will FAIL if models are not found
RUN mkdir -p "$RAPIDOCR_MODELS_PATH"
COPY ./document_processing_service/plugins/rapidocr-models/ ${RAPIDOCR_MODELS_PATH}/

# Verify required model files exist - FAIL BUILD if missing
RUN set -e; \
    echo "Verifying RapidOCR models..."; \
    REQUIRED_MODELS="ch_PP-OCRv3_det_infer.onnx ch_PP-OCRv3_rec_infer.onnx ch_ppocr_mobile_v2.0_cls_infer.onnx"; \
    MISSING_MODELS=""; \
    for MODEL in $REQUIRED_MODELS; do \
        MODEL_PATH="${RAPIDOCR_MODELS_PATH}/${MODEL}"; \
        if [ ! -f "$MODEL_PATH" ]; then \
            MISSING_MODELS="${MISSING_MODELS}\n  - ${MODEL}"; \
        fi; \
    done; \
    if [ -n "$MISSING_MODELS" ]; then \
        echo ""; \
        echo "╔════════════════════════════════════════════════════════════════╗"; \
        echo "║  ✗ ERROR: Required RapidOCR models NOT FOUND                  ║"; \
        echo "╚════════════════════════════════════════════════════════════════╝"; \
        echo ""; \
        echo "Missing models:"; \
        printf "$MISSING_MODELS\n"; \
        echo ""; \
        echo "Expected directly in: plugins/rapidocr-models/"; \
        echo "  - ch_PP-OCRv3_det_infer.onnx"; \
        echo "  - ch_PP-OCRv3_rec_infer.onnx"; \
        echo "  - ch_ppocr_mobile_v2.0_cls_infer.onnx"; \
        echo ""; \
        exit 1; \
    fi; \
    echo "✓ All required RapidOCR models found"; \
    ls -lh ${RAPIDOCR_MODELS_PATH}/*.onnx

# Docling layout models directory (pre-downloaded layout models for offline operation)
ENV DOCLING_ARTIFACTS_PATH=/opt/docling-models

# Copy Docling layout models from plugins/ directory
# REQUIRED: Docling layout models (docling-layout-heron, etc.) MUST be pre-downloaded
# Files should be directly in plugins/docling-models/docling-layout-heron/
# Run: python src/scripts/download_docling_models.py before building
RUN mkdir -p "$DOCLING_ARTIFACTS_PATH"
COPY ./document_processing_service/plugins/docling-models/ ${DOCLING_ARTIFACTS_PATH}/

# Verify Docling layout models - FAIL BUILD if missing
RUN set -e; \
    echo "Verifying Docling layout models..."; \
    REQUIRED_MODEL_DIR="${DOCLING_ARTIFACTS_PATH}/ds4sd--docling-layout-heron"; \
    REQUIRED_FILES="config.json model.safetensors preprocessor_config.json"; \
    MISSING_FILES=""; \
    \
    if [ ! -d "$REQUIRED_MODEL_DIR" ]; then \
        echo ""; \
        echo "╔════════════════════════════════════════════════════════════════╗"; \
        echo "║  ✗ ERROR: Docling layout model directory NOT FOUND            ║"; \
        echo "╚════════════════════════════════════════════════════════════════╝"; \
        echo ""; \
        echo "Expected directory: plugins/docling-models/ds4sd--docling-layout-heron/"; \
        echo ""; \
        echo "NOTE: Folder MUST be named 'ds4sd--docling-layout-heron' (double hyphen)"; \
        echo "      This matches HuggingFace repo pattern 'ds4sd/docling-layout-heron'"; \
        echo ""; \
        echo "To download models, run:"; \
        echo "  cd services/document_processing_service"; \
        echo "  pip install huggingface_hub"; \
        echo "  python src/scripts/download_docling_models.py"; \
        echo ""; \
        exit 1; \
    fi; \
    \
    for FILE in $REQUIRED_FILES; do \
        FILE_PATH="${REQUIRED_MODEL_DIR}/${FILE}"; \
        if [ ! -f "$FILE_PATH" ]; then \
            MISSING_FILES="${MISSING_FILES}\n  - ${FILE}"; \
        fi; \
    done; \
    \
    if [ -n "$MISSING_FILES" ]; then \
        echo ""; \
        echo "╔════════════════════════════════════════════════════════════════╗"; \
        echo "║  ✗ ERROR: Required Docling model files NOT FOUND              ║"; \
        echo "╚════════════════════════════════════════════════════════════════╝"; \
        echo ""; \
        echo "Missing files:"; \
        printf "$MISSING_FILES\n"; \
        echo ""; \
        echo "Expected in: plugins/docling-models/ds4sd--docling-layout-heron/"; \
        echo "  - config.json"; \
        echo "  - model.safetensors"; \
        echo "  - preprocessor_config.json"; \
        echo ""; \
        echo "To download models, run:"; \
        echo "  cd services/document_processing_service"; \
        echo "  pip install huggingface_hub"; \
        echo "  python src/scripts/download_docling_models.py"; \
        echo ""; \
        exit 1; \
    fi; \
    \
    MODEL_COUNT=$(find ${REQUIRED_MODEL_DIR} -type f | wc -l); \
    TOTAL_SIZE=$(du -sh ${REQUIRED_MODEL_DIR} | cut -f1); \
    echo "✓ All required Docling model files found (${MODEL_COUNT} files, ${TOTAL_SIZE})"; \
    echo "  - config.json"; \
    echo "  - model.safetensors"; \
    echo "  - preprocessor_config.json"

# Install heavy Python dependencies directly (cached layer for faster service builds)
RUN pip install --no-cache-dir docling[vlm] onnxruntime

# Hugging Face caches (only create directories for local VLM mode)
ENV HF_HOME=/opt/hf-cache \
    HUGGINGFACE_HUB_CACHE=/opt/hf-cache/hub \
    TRANSFORMERS_CACHE=/opt/hf-cache/transformers

# Conditionally download SmolVLM model to docling-models directory
# Docling expects models in artifacts_path with HF naming pattern (namespace--repo-name)
RUN if [ "$DOCLING_VLM_MODE" = "local" ]; then \
        echo "DOCLING_VLM_MODE=local: Downloading SmolVLM model in base image..." && \
        echo "Creating Hugging Face cache directories..." && \
        mkdir -p "$HF_HOME" "$HUGGINGFACE_HUB_CACHE" "$TRANSFORMERS_CACHE" && \
        echo "Installing huggingface_hub for model download..." && \
        pip install --no-cache-dir huggingface_hub && \
        echo "Downloading SmolVLM model to docling-models directory..." && \
        python -c "from huggingface_hub import snapshot_download; snapshot_download(repo_id='HuggingFaceTB/SmolVLM-256M-Instruct', local_dir='$DOCLING_ARTIFACTS_PATH/HuggingFaceTB--SmolVLM-256M-Instruct', local_dir_use_symlinks=False, cache_dir='$HUGGINGFACE_HUB_CACHE')" && \
        echo "SmolVLM model downloaded successfully to $DOCLING_ARTIFACTS_PATH/HuggingFaceTB--SmolVLM-256M-Instruct"; \
    else \
        echo "DOCLING_VLM_MODE=${DOCLING_VLM_MODE}: Skipping SmolVLM model download (using remote VLM APIs)"; \
    fi

WORKDIR /app

# Note: Application code and final setup is done in the service Dockerfile

